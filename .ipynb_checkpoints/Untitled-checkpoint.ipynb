{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MROiPUM - Projekt numer 1 - AdaBoost dla pełnych danych oraz sieć neuronowa MLP\n",
    "## Autorzy - Jakub Raban, Bartłomiej Strózik, gr. pt. 14:40 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie danych do pracy\n",
    "Zaimportowanie danych i wstępna obróbka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>who</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PICARD V.O.</td>\n",
       "      <td>Captain's log, stardate 42353.7. Our destinat...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PICARD V.O.</td>\n",
       "      <td>My orders are to examine Farpoint, a starbase...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PICARD V.O.</td>\n",
       "      <td>acquainted with my new command, this Galaxy C...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PICARD V.O.</td>\n",
       "      <td>I am still somewhat in awe of its size and co...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PICARD V.O.</td>\n",
       "      <td>several key positions, most notably ...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110167</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Would you care to deal?</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110168</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>Oh... thank you.</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110170</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>I should have done this a long time ago. I wa...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110171</th>\n",
       "      <td>TROI</td>\n",
       "      <td>You were always welcome.</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110173</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>So. Five card stud, nothing wild. The sky's t...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68486 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 who                                               text  \\\n",
       "1        PICARD V.O.   Captain's log, stardate 42353.7. Our destinat...   \n",
       "3        PICARD V.O.   My orders are to examine Farpoint, a starbase...   \n",
       "5        PICARD V.O.   acquainted with my new command, this Galaxy C...   \n",
       "7        PICARD V.O.   I am still somewhat in awe of its size and co...   \n",
       "9        PICARD V.O.            several key positions, most notably ...   \n",
       "...              ...                                                ...   \n",
       "110167          DATA                            Would you care to deal?   \n",
       "110168        PICARD                                   Oh... thank you.   \n",
       "110170        PICARD   I should have done this a long time ago. I wa...   \n",
       "110171          TROI                           You were always welcome.   \n",
       "110173        PICARD   So. Five card stud, nothing wild. The sky's t...   \n",
       "\n",
       "          type  \n",
       "1       speech  \n",
       "3       speech  \n",
       "5       speech  \n",
       "7       speech  \n",
       "9       speech  \n",
       "...        ...  \n",
       "110167  speech  \n",
       "110168  speech  \n",
       "110170  speech  \n",
       "110171  speech  \n",
       "110173  speech  \n",
       "\n",
       "[68486 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('TNG.csv', header=0)\n",
    "# usunięcie kolumny 'scenedetails' która nie ma żadnych wartości\n",
    "data.drop(labels='scenedetails', axis=1, inplace=True)\n",
    "# wybranie jedynie interesujących nas kolumn: [type, who, text]\n",
    "speeches = data[['who', 'text', 'type']]\n",
    "# usunięcie ze speeches wierszy mających wartość pustą (NA, NaN) w dowolnej kolumnie\n",
    "speeches = speeches[speeches.notnull().all(axis=1)]\n",
    "# zostawiamy tylko wiersze z mówionym tekstem\n",
    "speeches = speeches[speeches['type'] == 'speech']\n",
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzamy które osoby mówią najczęściej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " PICARD                12611\n",
       " RIKER                  7257\n",
       " DATA                   6416\n",
       " GEORDI                 4591\n",
       " WORF                   3910\n",
       " BEVERLY                3403\n",
       " TROI                   3377\n",
       " WESLEY                 1448\n",
       " GUINAN                  538\n",
       " TASHA                   507\n",
       " PULASKI                 478\n",
       " Q                       462\n",
       " COMPUTER VOICE          460\n",
       " O'BRIEN                 444\n",
       " PICARD (V.O.)           411\n",
       " RO                      402\n",
       " BARCLAY                 364\n",
       " LWAXANA                 301\n",
       " RIKER'S COM VOICE       219\n",
       " PICARD'S COM VOICE      212\n",
       " VASH                    206\n",
       " ALEXANDER               204\n",
       " K'EHLEYR                179\n",
       "Name: who, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches['who'].value_counts()[:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby lepiej sklasyfikować dane, usuwamy z nazw osób mówiących dopiski, tj. ```V.O.```, ```(V.O.)```, ```'S COM VOICE```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " PICARD            13234\n",
       " RIKER              7533\n",
       " DATA               6567\n",
       " GEORDI             4748\n",
       " WORF               4012\n",
       " BEVERLY            3494\n",
       " TROI               3409\n",
       " WESLEY             1466\n",
       " GUINAN              539\n",
       " TASHA               534\n",
       " PULASKI             492\n",
       " O'BRIEN             487\n",
       " Q                   462\n",
       " COMPUTER VOICE      461\n",
       " RO                  404\n",
       " BARCLAY             371\n",
       " LWAXANA             304\n",
       " VASH                210\n",
       " ALEXANDER           204\n",
       " K'EHLEYR            179\n",
       " JELLICO             167\n",
       " MORIARTY            149\n",
       " LORE                140\n",
       "Name: who, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_metadata_from_speaking_character_name(character):\n",
    "    ds = [\" (V.O.)\", \"V.O.\", \"'S COM VOICE\"]\n",
    "    for d in ds:\n",
    "        if character.endswith(d):\n",
    "            return character[:-len(d)]\n",
    "    return character\n",
    "\n",
    "speeches['who'] = speeches['who'].apply(remove_metadata_from_speaking_character_name)\n",
    "speeches['who'].value_counts()[:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zostawiamy mowy 20 najczęściej przewijających się postaci i usuwamy już niepotrzebą kolumnę ```type```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/.local/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>who</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>You will agree, Data, that Starfleet's instru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Difficult ... how so? Simply solve the myster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>As simple as that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TROI</td>\n",
       "      <td>Farpoint Station. Even the name sounds myster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>The problem, Data, is that another life form ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110167</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Would you care to deal?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110168</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>Oh... thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110170</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>I should have done this a long time ago. I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110171</th>\n",
       "      <td>TROI</td>\n",
       "      <td>You were always welcome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110173</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>So. Five card stud, nothing wild. The sky's t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49110 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            who                                               text\n",
       "12       PICARD   You will agree, Data, that Starfleet's instru...\n",
       "13         DATA   Difficult ... how so? Simply solve the myster...\n",
       "14       PICARD                                 As simple as that.\n",
       "15         TROI   Farpoint Station. Even the name sounds myster...\n",
       "16       PICARD   The problem, Data, is that another life form ...\n",
       "...         ...                                                ...\n",
       "110167     DATA                            Would you care to deal?\n",
       "110168   PICARD                                   Oh... thank you.\n",
       "110170   PICARD   I should have done this a long time ago. I wa...\n",
       "110171     TROI                           You were always welcome.\n",
       "110173   PICARD   So. Five card stud, nothing wild. The sky's t...\n",
       "\n",
       "[49110 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers = list(speeches['who'].value_counts()[:20].index)\n",
    "speeches = speeches[speeches['who'].isin(speakers)]\n",
    "speeches.drop(labels='type', axis=1, inplace=True)\n",
    "speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą funkcji ```factorize``` kodujemy każdą postać jako liczbę naturalną"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "      <th>character_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>You will agree, Data, that Starfleet's instru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Difficult ... how so? Simply solve the myster...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>As simple as that.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TROI</td>\n",
       "      <td>Farpoint Station. Even the name sounds myster...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PICARD</td>\n",
       "      <td>The problem, Data, is that another life form ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character                                               text  character_id\n",
       "12    PICARD   You will agree, Data, that Starfleet's instru...             0\n",
       "13      DATA   Difficult ... how so? Simply solve the myster...             1\n",
       "14    PICARD                                 As simple as that.             0\n",
       "15      TROI   Farpoint Station. Even the name sounds myster...             2\n",
       "16    PICARD   The problem, Data, is that another life form ...             0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches = speeches.rename(columns={'who': 'character'})\n",
    "speeches['character_id'] = speeches['character'].factorize()[0]\n",
    "character_id_df = speeches[['character', 'character_id']].drop_duplicates().sort_values('character_id')\n",
    "character_to_id = dict(character_id_df.values)\n",
    "id_to_character = dict(character_id_df[['character_id', 'character']].values)\n",
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zgodnie z treścią zadania zostawiamy 18 000 próbek. Mamy więc 18 000 próbek i 20 klas. Aby zasymulować różne budżety czasowe tworzymy również zbiór mniejszy (10 000 próbek) oraz większy (25 000 próbek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_normal = speeches.sample(18000, random_state=18000)\n",
    "speeches_small = speeches.sample(10000, random_state=10000)\n",
    "speeches_large = speeches.sample(25000, random_state=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby dokonać klasyfikacji należy zamienić wypowiadany przez postacie tekst na wektory. Jednym ze sposobów na osiągnięcie tego jest zastosowanie wektoryzacji TF\\*IDF, która najpierw zlicza ilość wystąpień wszystkich słów w wypowiedziach wszystkich postaci, a następnie słowom z poszczególnych wypowiedzi przypisuje wagę tym większą, im rzadziej pojawia się w ogóle wystąpień"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 6189)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=3, norm='l2', encoding='utf-8', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(speeches_normal['text']).toarray()\n",
    "labels = speeches_normal['character']\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(speeches['text'], speeches['character'], random_state=42)\n",
    "# count_vectorizer = CountVectorizer()\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# X_test_counts = count_vectorizer.fit_transform(X_test)\n",
    "# X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonujemy klasyfikacji za pomocą trzech klasyfikatorów: AdaBoost, sieci neuronowej MLP oraz dodatkowo za pomocą wielomianowego naiwnego klasyfikatora Bayesowskiego, który to jest typowo używany do klasyfikacji tekstu. Dla każdego klasyfikatora dokonujemy walidacji krzyżowej przy podziale zbioru na 5 części oraz obliczamy następujące metryki:\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- F1\n",
    "- ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jakub/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jakub/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jakub/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jakub/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    AdaBoostClassifier(),\n",
    "#     MLPClassifier(alpha=0.7, max_iter=400),\n",
    "#     MultinomialNB(),\n",
    "]\n",
    "accuracies = []\n",
    "for model in models:\n",
    "    accuracy_scores = cross_validate(model, features, labels, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc_ovr_weighted'], cv=5)\n",
    "    accuracies.append(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej przedstawienie uśrednionych wyników cross-validation w formie tabelarycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.292625</td>\n",
       "      <td>0.204835</td>\n",
       "      <td>0.292625</td>\n",
       "      <td>0.159535</td>\n",
       "      <td>0.507194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.272250</td>\n",
       "      <td>0.251628</td>\n",
       "      <td>0.272250</td>\n",
       "      <td>0.258670</td>\n",
       "      <td>0.630907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayes</th>\n",
       "      <td>0.324125</td>\n",
       "      <td>0.342590</td>\n",
       "      <td>0.324125</td>\n",
       "      <td>0.225131</td>\n",
       "      <td>0.668576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy  Precision    Recall        F1   ROC-AUC\n",
       "AdaBoost  0.292625   0.204835  0.292625  0.159535  0.507194\n",
       "MLP       0.272250   0.251628  0.272250  0.258670  0.630907\n",
       "Bayes     0.324125   0.342590  0.324125  0.225131  0.668576"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = [[score[metric].mean() for metric in ['test_accuracy', 'test_precision_weighted', 'test_recall_weighted', 'test_f1_weighted', 'test_roc_auc_ovr_weighted']] for score in accuracies]\n",
    "pd.DataFrame(summary, columns=['Accuracy', 'Precision', 'Recall', 'F1', 'ROC-AUC'], index=['AdaBoost', 'MLP', 'Bayes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W dalszej części porównujemy działanie klasyfikatorów mając do dyspozycji 3 różne budżety czasowe: mały, średni i duży"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51143        RIKER\n",
       "7095         RIKER\n",
       "84129      BEVERLY\n",
       "24018         DATA\n",
       "8524          DATA\n",
       "            ...   \n",
       "31912      O'BRIEN\n",
       "1284        WESLEY\n",
       "71749       WESLEY\n",
       "107667      PICARD\n",
       "70451        RIKER\n",
       "Name: character, Length: 18000, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 3057 and input n_features is 804 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-31398803b85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0maccuracies2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[0m\u001b[1;32m    697\u001b[0m                        for estimator in self.estimators_)\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[0m\u001b[1;32m    697\u001b[0m                        for estimator in self.estimators_)\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_samme_proba\u001b[0;34m(estimator, n_classes, X)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \"\"\"\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;31m# Displace zero probabilities so the log is defined.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[1;32m    904\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[1;32m    389\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 3057 and input n_features is 804 "
     ]
    }
   ],
   "source": [
    "accuracies2 = []\n",
    "for subset in [speeches_small, speeches_normal, speeches_large]:\n",
    "    for model in models[:2]:  # AdaBoost, MLP\n",
    "        X_train, X_test, y_train, y_test = train_test_split(subset, subset['character'], train_size=0.8)\n",
    "        features = tfidf.fit_transform(X_train['text']).toarray()\n",
    "        labels = y_train\n",
    "        model.fit(features, labels)\n",
    "        accuracies2.append(model.score(tfidf.fit_transform(X_test['text']).toarray(), y_test))\n",
    "        break\n",
    "    break\n",
    "accuracies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tut3",
   "language": "python",
   "name": "ml-tut3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
